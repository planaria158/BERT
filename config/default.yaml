
model_params:
  n_embd: 64
  n_layer: 6
  n_head : 8
  embd_pdrop : 0.1
  resid_pdrop : 0.1
  attn_pdrop : 0.1
  model_type : 'bert'
  vocab_size : 50257 # openai's model vocabulary
  block_size : 128  #1024  # openai's model block_size
  mask_prob : 0.15
  weight_decay : 0.1
  learning_rate : 0.0001
  betas : [0.9, 0.95]
  device : 'cuda'
  batch_size: 32
  num_workers: 5
  grad_norm_clip : 1.0
  max_iters : 10000
  generate_every : 500
  work_dir : './out/chargpt'
  seed : 3407
