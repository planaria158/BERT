{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some work on the scFv data and Dataset\n",
    "### The scFv antibody sequence/binding affinity data from a-alpha-Bio's Nature Communications paper\n",
    "quantitative binding scores of scFv-format antibodies against a SARS-CoV-2 target peptide collected via an AlphaSeq assay\n",
    "\n",
    "#### Two datasets:\n",
    "* antibody_dataset_1 : 1109000 MITLL_AAlphaBio_Ab_Binding_dataset.csv rows\n",
    "* antibody_dataset_2 : 1903928 MITLL_AAlphaBio_Ab_Binding_dataset2.csv rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "#### Affinities\n",
    "* reported values are log10(Kd(nM))\n",
    "\n",
    "* delG = RT log10(Kd)    # or -RT log10(Ka)\n",
    "* R = 0.008314 kJ mol-1 (1.98722 cal/K•mol)\n",
    "* T = 298.15 room temp\n",
    "* if Kd = 1.909nM, then delG = -5.16 kcal/mol binding free energy\n",
    "* \"Data include antibodies with predicted affinity measurements ranging from 37 pM to 22 mM\"\n",
    "   * 37pm corresponds to delG = -6.18 kcal/mol binding free energy.\n",
    "   * 22mM corresponds to delG = -0.98 kcal/mol binding free energy.\n",
    "* For reference, the biotin/avidin binding free energy is one of the strongest in nature with absolute free energy of binding, −20.4 kcal/mol\n",
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/anaconda3/envs/avm-dvm/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/mark/anaconda3/envs/avm-dvm/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "import math\n",
    "# pd.options.mode.copy_on_write = True # to avoid SettingWithCopyWarning\n",
    "import os\n",
    "import yaml\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.core import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_embd': 512, 'regress_head_drop': 0.1, 'vocab_size': 23, 'block_size': 91, 'mask_prob': 0.0, 'weight_decay': 0.1, 'learning_rate': 0.0001, 'lr_gamma': 0.9985, 'betas': [0.9, 0.95], 'accelerator': 'gpu', 'devices': 2, 'batch_size': 1024, 'num_workers': 20, 'grad_norm_clip': 1.0, 'num_epochs': 100, 'checkpoint_every_n_train_steps': 100, 'save_top_k': 1, 'monitor': 'loss', 'mode': 'min', 'log_dir': './lightning_logs/', 'log_every_nsteps': 100, 'checkpoint_pretrained': '/home/mark/dev/myBERT/lightning_logs/pre-train/checkpoints/epoch=4-step=252700.ckpt', 'checkpoint_name': 'None', 'seed': 3407}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Read the config\n",
    "#\n",
    "config_path = './config/fine_tune_config.yaml'  \n",
    "with open(config_path, 'r') as file:\n",
    "    try:\n",
    "        config = yaml.safe_load(file)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "config = config['model_params']\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Code fragments taken from:\n",
    "# * https://github.com/barneyhill/minBERT\n",
    "# * https://github.com/karpathy/minGPT\n",
    "\n",
    "# protein sequence data taken from:\n",
    "# * https://www.nature.com/articles/s41467-023-39022-2\n",
    "# * https://zenodo.org/records/7783546\n",
    "#--------------------------------------------------------\n",
    "\n",
    "class scFv_Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of amino acid sequences and binding energies\n",
    "    \"\"\"\n",
    "    def __init__(self, config, csv_file_path, skiprows=0):  \n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        print('reading the data from:', csv_file_path)\n",
    "        self.df = pd.read_csv(csv_file_path, skiprows=skiprows)\n",
    "        \n",
    "        # 20 naturally occuring amino acids in human proteins plus MASK token, \n",
    "        # 'X' is a special token for unknown amino acids, and CLS token is for classification\n",
    "        self.chars = ['CLS', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'X', '[MASK]']\n",
    "        print('vocabulary:', self.chars)\n",
    "\n",
    "        data_size, vocab_size = self.df.shape[0], len(self.chars)\n",
    "        print('data has %d rows, %d vocab size (unique).' % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = { ch:i for i,ch in enumerate(self.chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(self.chars) }\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.config['block_size']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0] #len(self.data) - self.config['block_size']\n",
    "\n",
    "    \"\"\" Returns data, mask pairs used for Masked Language Model training \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.df.loc[idx, 'Sequence']\n",
    "        affinity = self.df.loc[idx, 'Pred_affinity']\n",
    "        assert not math.isnan(affinity), 'affinity is nan'\n",
    "        assert affinity >= 0.0, 'affinity is negative'\n",
    "        assert len(seq) >= self.config['block_size'], 'sequence is too short'\n",
    "\n",
    "        # get a randomly located block_size-1 substring from the sequence\n",
    "        # '-1' so we can prepend the CLS token to the start of the encoded string\n",
    "        if len(seq) == self.config['block_size']-1:\n",
    "            chunk = seq\n",
    "        else:\n",
    "            start_idx = np.random.randint(0, len(seq) - (self.config['block_size'] - 1))\n",
    "            chunk = seq[start_idx:start_idx + self.config['block_size']-1]\n",
    "\n",
    "        # encode every character to an integer\n",
    "        dix = torch.tensor([self.stoi[s] for s in chunk], dtype=torch.long)\n",
    "\n",
    "        # prepend the CLS token to the sequence\n",
    "        dix = torch.cat((torch.tensor([self.stoi['CLS']], dtype=torch.long), dix))\n",
    "\n",
    "        mask = None\n",
    "        if self.config['mask_prob'] > 0:\n",
    "            # get number of tokens to mask\n",
    "            n_pred = max(1, int(round(self.config['block_size']*self.config['mask_prob'])))\n",
    "\n",
    "            # indices of the tokens that will be masked (a random selection of n_pred of the tokens)\n",
    "            masked_idx = torch.randperm(self.config['block_size']-1, dtype=torch.long, )[:n_pred]\n",
    "            masked_idx += 1  # so we never mask the CLS token\n",
    "\n",
    "            mask = torch.zeros_like(dix)\n",
    "\n",
    "            # copy the actual tokens to the mask\n",
    "            mask[masked_idx] = dix[masked_idx]\n",
    "            \n",
    "            # ... and overwrite them with MASK token in the data\n",
    "            dix[masked_idx] = self.stoi[\"[MASK]\"]\n",
    "\n",
    "        # print('dix shape:', dix.shape, ', affinity:', affinity)\n",
    "        # print('dix type:', dix.dtype, ', affinity type:', type(affinity))\n",
    "        return dix, affinity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/test_set.csv'\n",
    "train_path = './data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/train_set.csv'\n",
    "dataset = scFv_Dataset(config, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.__len__())\n",
    "dix, affinity = dataset.__getitem__(0)\n",
    "print(dix[:10])\n",
    "print(affinity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "batch = next(data_iter)\n",
    "dix, affinity = batch\n",
    "print(dix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## antibody_dataset_1\n",
    "### The scFv antibody sequence/binding affinity data in the AlphaSeq experimental assay data\n",
    "\n",
    "#### Some observations:\n",
    "* total rows: 1109000\n",
    "\n",
    "* Number of unique sequences based on actual sequence: 104968\n",
    "* Number of unique sequences using the POI sequence label: 104972\n",
    "* There are between 8-20 instances of each sequence\n",
    "* Number of rows where affinity is not NAN : 340100  (most of original set have nan affinities!??)\n",
    "    * number of unique sequences in this subset: 87211\n",
    "    \n",
    "    * number of unique POIs in this subset: 87215\n",
    "    * for each of these unique sequences, there are multiple binding affinity values\n",
    "         * seq_dict: first entry\n",
    "         \n",
    "         *  seq 1 : , num affinity values: 6 , values: {0.8661294738454064, 0.9084780753465632, 0.9577932321017446, 3.9196288144788087, .....}\n",
    "         *  -RTlog10(3.9) = -4.98 kcal/mol binding free energy\n",
    "         *  -RTlog10(0.866) = -5.36 kcal/mol\n",
    "         *  for reference kT = 0.6 kcal/mol so this difference is on the order of kT\n",
    "    * use the mean value for affinity (or median)?\n",
    "\n",
    "\n",
    "#### The paper:\n",
    "*  https://www.nature.com/articles/s41597-022-01779-4#Tab4 lists 71384 \n",
    "* \"Of the 119,600 designs, 104,972 were successfully built in to the AlphaSeq library and target binding was subsequently measured with 71,384 designs\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc binding free energy (in kcal/mol) from Kd \n",
    "# affinity is Kd in nM\n",
    "R = 1.98722 # cal/(mol*K)\n",
    "T = 298.15 # K\n",
    "def free_energy(Kd):\n",
    "    delG = R * T * math.log10(Kd * 1e-9)    # or -RT log10(Ka)\n",
    "    return delG/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_energy(0.005687)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1109000, 14)\n",
      "Index(['POI', 'Sequence', 'Target', 'Assay', 'Replicate', 'Pred_affinity',\n",
      "       'HC', 'LC', 'CDRH1', 'CDRH2', 'CDRH3', 'CDRL1', 'CDRL2', 'CDRL3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# The experimental data from AlphaSeq Nature study.\n",
    "data_path = './data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/MITLL_AAlphaBio_Ab_Binding_dataset.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                               1109000\n",
       "unique                                               104968\n",
       "top       EVQLVETGGGLVQPGGSLRLSCAASGFTLNSYGISWVRQAPGKGPE...\n",
       "freq                                                     44\n",
       "Name: Sequence, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sequence'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on distribution of sequence lengths\n",
    "# loop through the rows using iterrows()\n",
    "def get_misc_info(df):\n",
    "    seq_lens = []\n",
    "    seq_set = set()\n",
    "    poi_dict = {}\n",
    "    for index, row in df.iterrows():\n",
    "        seq = row['Sequence']\n",
    "        poi = row['POI']\n",
    "        seq_lens.append(len(seq))\n",
    "        seq_set.add(seq)\n",
    "        if poi not in poi_dict:\n",
    "            poi_dict[poi] = 1\n",
    "        else:\n",
    "            poi_dict[poi] += 1\n",
    "\n",
    "    print('number of unique sequences:', len(seq_set))\n",
    "    print('number of unique POIs:', len(poi_dict))\n",
    "\n",
    "    counts = list(poi_dict.values())\n",
    "    counts.sort()\n",
    "    print('min count:', counts[0], ', max count:', counts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique sequences: 104968\n",
      "number of unique POIs: 104972\n",
      "min count: 8 , max count: 20\n"
     ]
    }
   ],
   "source": [
    "# The entire antibody_dataset_1 csv file.\n",
    "get_misc_info(df)\n",
    "\n",
    "# results:\n",
    "# number of unique sequences: 104968\n",
    "# number of unique POIs: 104972\n",
    "# min count: 8 , max count: 20\n",
    "#\n",
    "# Note: 104,972 agrees with the number listed in the Nature paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting shape: (1109000, 14)\n",
      "(340100, 14)\n",
      "after removing nans: (340100, 14)\n",
      "number of unique sequences: 87211\n",
      "number of unique POIs: 87215\n",
      "min count: 1 , max count: 12\n"
     ]
    }
   ],
   "source": [
    "# The entire antibody_dataset_1 csv file.\n",
    "print('starting shape:', df.shape)\n",
    "\n",
    "# Drop NANs in pred affinity column\n",
    "df_clean = df.dropna(subset=['Pred_affinity'])\n",
    "print(df_clean.shape)\n",
    "print('after removing nans:', df_clean.shape)\n",
    "get_misc_info(df_clean)\n",
    "\n",
    "# starting shape: (1109000, 14)\n",
    "# (340100, 14)\n",
    "# after removing nans: (340100, 14)\n",
    "# number of unique sequences: 87211\n",
    "# number of unique POIs: 87215\n",
    "# min count: 1 , max count: 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len seq_dict: 87211\n",
      "len poi_dict: 87211\n",
      "seq_dict: first few entries\n",
      "0 : , num values: 6 , values: {0.8661294738454064, 0.9084780753465632, 0.9577932321017446, 3.9196288144788087, 4.914154179746138, 5.723329881345849}\n",
      "1 : , num values: 12 , values: {1.4505434853677084, 1.4248811789665847, 3.736022319355234, 4.208875709332999, 4.1969741379377705, 5.053950729480507, 4.690954801766403, 4.225537246160031, 1.5815625508664832, 4.28826022838054, 4.9744274864843865, 5.007441109453564}\n",
      "2 : , num values: 7 , values: {1.7899955194100752, 2.263831676684976, 3.8100026599168384, 1.7935568167187643, 5.380368626969683, 3.908238706063365, 3.955892163776589}\n",
      "3 : , num values: 7 , values: {1.7042172390142856, 1.7621526510488703, 1.825962828947824, 4.417285434453146, 4.549318549448136, 4.78409345871224, 5.106323925284952}\n",
      "4 : , num values: 8 , values: {1.6254710084772963, 1.6099233031912252, 3.4684917740243204, 4.330292501814343, 1.68272713929683, 3.524101524593373, 4.714744238136452, 3.723603473569288}\n",
      "5 : , num values: 6 , values: {0.4551541513453721, 0.7310596515493035, 0.6008264973911501, 4.527392653894088, 4.36620158798099, 4.911376592348088}\n",
      "6 : , num values: 7 , values: {0.7088969404081613, 0.837280699483502, 0.7957881489955358, 2.793021321788, 4.902049859012823, 4.129883399102775, 4.157092581733772}\n",
      "poi_dict: first few entries\n",
      "0 : , num values: 6 , values: {0.8661294738454064, 0.9084780753465632, 0.9577932321017446, 3.9196288144788087, 4.914154179746138, 5.723329881345849}\n",
      "1 : , num values: 12 , values: {1.4505434853677084, 1.4248811789665847, 3.736022319355234, 4.208875709332999, 4.1969741379377705, 5.053950729480507, 4.690954801766403, 4.225537246160031, 1.5815625508664832, 4.28826022838054, 4.9744274864843865, 5.007441109453564}\n",
      "2 : , num values: 7 , values: {1.7899955194100752, 2.263831676684976, 3.8100026599168384, 1.7935568167187643, 5.380368626969683, 3.908238706063365, 3.955892163776589}\n",
      "3 : , num values: 7 , values: {1.7042172390142856, 1.7621526510488703, 1.825962828947824, 4.417285434453146, 4.549318549448136, 4.78409345871224, 5.106323925284952}\n",
      "4 : , num values: 8 , values: {1.6254710084772963, 1.6099233031912252, 3.4684917740243204, 4.330292501814343, 1.68272713929683, 3.524101524593373, 4.714744238136452, 3.723603473569288}\n",
      "5 : , num values: 6 , values: {0.4551541513453721, 0.7310596515493035, 0.6008264973911501, 4.527392653894088, 4.36620158798099, 4.911376592348088}\n",
      "6 : , num values: 7 , values: {0.7088969404081613, 0.837280699483502, 0.7957881489955358, 2.793021321788, 4.902049859012823, 4.129883399102775, 4.157092581733772}\n"
     ]
    }
   ],
   "source": [
    "# Examine the values for affinity for each repeat of each sequence.\n",
    "seq_lens = []\n",
    "seq_set = set()\n",
    "seq_dict = {} # will contain a set for binding energies for each unique sequence\n",
    "poi_dict = {} # will contain a set for binding energies for each unique POI\n",
    "for index, row in df_clean.iterrows():\n",
    "    seq = row['Sequence']\n",
    "    poi = row['POI']\n",
    "    affinity = row['Pred_affinity']\n",
    "    if seq not in seq_dict:\n",
    "        seq_dict[seq] = set()\n",
    "        seq_dict[seq].add(affinity)\n",
    "    else:\n",
    "        seq_dict[seq].add(affinity)\n",
    "\n",
    "    if poi not in poi_dict:\n",
    "        poi_dict[poi] = set()\n",
    "        poi_dict[poi].add(affinity)\n",
    "    else:\n",
    "        poi_dict[poi].add(affinity)\n",
    "\n",
    "print('len seq_dict:', len(seq_dict))\n",
    "print('len poi_dict:', len(seq_dict))\n",
    "\n",
    "print('seq_dict: first few entries')\n",
    "for i, (k, v) in enumerate(seq_dict.items()):\n",
    "    assert len(v) > 0, 'empty set for sequence'\n",
    "    print(i, ':', ', num values:', len(v), ', values:', v)\n",
    "\n",
    "    if i > 5:\n",
    "        break\n",
    "\n",
    "\n",
    "print('poi_dict: first few entries')\n",
    "for i, (k, v) in enumerate(poi_dict.items()):\n",
    "    assert len(v) > 0, 'empty set for POI'\n",
    "    print(i, ':', ', num values:', len(v), ', values:', v)\n",
    "\n",
    "    if i > 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sequences with just 1 binding affinity value: 27299\n"
     ]
    }
   ],
   "source": [
    "# Histogram of the number of binding affinity values for the unique sequences (that have binding affinities != NAN)\n",
    "#\n",
    "lengths = [len(v) for k,v in seq_dict.items()]\n",
    "lengths.sort()\n",
    "blah = plt.hist(lengths, bins=20)\n",
    "plt.show()\n",
    "\n",
    "print('number of sequences with just 1 binding affinity value:', int(blah[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Final training set:\n",
    "* 87211 sequences\n",
    "* affinity will be the mean of each sequence’s multiple affinities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len seq_dict: 87211\n",
      "seq_dict: first few entries\n",
      "0 : , num values: 6 , values: {0.8661294738454064, 0.9084780753465632, 0.9577932321017446, 3.9196288144788087, 4.914154179746138, 5.723329881345849}\n",
      "1 : , num values: 12 , values: {1.4505434853677084, 1.4248811789665847, 3.736022319355234, 4.208875709332999, 4.1969741379377705, 5.053950729480507, 4.690954801766403, 4.225537246160031, 1.5815625508664832, 4.28826022838054, 4.9744274864843865, 5.007441109453564}\n",
      "2 : , num values: 7 , values: {1.7899955194100752, 2.263831676684976, 3.8100026599168384, 1.7935568167187643, 5.380368626969683, 3.908238706063365, 3.955892163776589}\n",
      "3 : , num values: 7 , values: {1.7042172390142856, 1.7621526510488703, 1.825962828947824, 4.417285434453146, 4.549318549448136, 4.78409345871224, 5.106323925284952}\n",
      "\n",
      "0 : EVQLVETGGGLVQPGGSLRL , mean: 2.8815856094774186\n",
      "1 : EVQLVETGGGLVQPGGSLRL , mean: 3.736619248629351\n",
      "2 : EVQLVETGGGLVQPGGSLRL , mean: 3.2716980242200413\n",
      "3 : EVQLVETGGGLVQPGGSLRL , mean: 3.4499077267013507\n",
      "min length: 240 , max length: 249\n",
      "[158, 163, 190, 232]\n"
     ]
    }
   ],
   "source": [
    "print('len seq_dict:', len(seq_dict))\n",
    "print('seq_dict: first few entries')\n",
    "for i, (k, v) in enumerate(seq_dict.items()):\n",
    "    assert len(v) > 0, 'empty set for sequence'\n",
    "    print(i, ':', ', num values:', len(v), ', values:', v)\n",
    "    if i > 2:\n",
    "        break\n",
    "\n",
    "print()\n",
    "# calc the mean of the binding affinities for each sequence\n",
    "seq_mean_dict = {}\n",
    "for k,v in seq_dict.items():\n",
    "    seq_mean_dict[k] = np.mean(list(v))\n",
    "\n",
    "# print the first few entries\n",
    "for i, (k, v) in enumerate(seq_mean_dict.items()):\n",
    "    print(i, ':', k[:20], ', mean:', v)\n",
    "    if i > 2:\n",
    "        break    \n",
    "\n",
    "lengths = [len(k) for k,v in seq_mean_dict.items()]\n",
    "lengths.sort()\n",
    "print('min length:', lengths[0], ', max length:', lengths[-1])\n",
    "\n",
    "seqs = [k for k,v in seq_mean_dict.items()]\n",
    "s1 = seqs[45]\n",
    "s2 = seqs[2000]\n",
    "diff = [i for i in range(len(s1)) if s1[i] != s2[i]]\n",
    "print(diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train and test sets and save as csv files\n",
    "seqs = [k for k,v in seq_mean_dict.items()]\n",
    "affinities = [v for k,v in seq_mean_dict.items()]\n",
    "\n",
    "df = pd.DataFrame({'Sequence': seqs, 'Pred_affinity': affinities})\n",
    "\n",
    "# Remove enries with negative affinity values\n",
    "df_clean = df[df['Pred_affinity'] > 0]\n",
    "print(df_clean.describe())\n",
    "\n",
    "# Train/test split 90/10\n",
    "# train_df = df_clean.sample(frac=0.9, random_state=42)\n",
    "# test_df = df_clean.drop(train_df.index)\n",
    "# print('train:', train_df.shape, ', test:', test_df.shape)\n",
    "\n",
    "# save to csv\n",
    "# train_df.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/train_set.csv', index=False)\n",
    "# test_df.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/test_set.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(4)\n",
    "print(a.shape)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all rows that contain NAN in the Pred_affinity column.\n",
    "Yikes!  ~75% of the dataframe has NANs in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pred_affinity'].isna().sum()\n",
    "\n",
    "aff = df['Pred_affinity']\n",
    "# c = c[~np.isnan(c)]\n",
    "for i, a in enumerate(aff):\n",
    "    if np.isnan(a):\n",
    "        print(i, a)\n",
    "        break\n",
    "\n",
    "print(df.loc[23925])  #, 'Pred_affinity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aff.shape)\n",
    "aff = aff[~np.isnan(aff)]\n",
    "print(aff.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=['Pred_affinity'])\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df_clean.sample(frac = 0.10)\n",
    "train_set = df_clean.drop(test_set.index)\n",
    "\n",
    "print(test_set.shape)\n",
    "print(train_set.shape)\n",
    "test_set.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/test_set.csv')\n",
    "train_set.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()   #.isinf().sum()\n",
    "\n",
    "# ds = df.isin([np.inf, -np.inf]) \n",
    "# print(ds.shape) \n",
    "  \n",
    "# # printing the count of infinity values \n",
    "# print() \n",
    "# print(\"printing the count of infinity values\") \n",
    "  \n",
    "# count = np.isinf(df).values.sum() \n",
    "# print(\"It contains \" + str(count) + \" infinite values\") \n",
    "  \n",
    "# # counting infinity in a particular column name \n",
    "# c = np.isinf(df['Weight']).values.sum() \n",
    "# print(\"It contains \" + str(c) + \" infinite values\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on distribution of sequence lengths\n",
    "# loop through the rows using iterrows()\n",
    "print(df.shape)\n",
    "seq_lens = []\n",
    "seq_set = set()\n",
    "for index, row in df.iterrows():\n",
    "    seq = row['Sequence']\n",
    "    seq_lens.append(len(seq))\n",
    "    seq_set.add(seq)\n",
    "\n",
    "print(len(seq_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(seq_lens, bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = df.sample(frac = 0.10)\n",
    "# train_set = df.drop(test_set.index)\n",
    "\n",
    "# print(test_set.shape)\n",
    "# print(train_set.shape)\n",
    "# test_set.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/test_set.csv')\n",
    "# train_set.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_1/train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_2/MITLL_AAlphaBio_Ab_Binding_dataset2.csv'\n",
    "df = pd.read_csv(data_path, skiprows=6)\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df_clean = df.dropna(subset=['Pred_affinity'])\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = df_2.sample(frac = 0.10)\n",
    "# train_set = df_2.drop(test_set.index)\n",
    "\n",
    "# print(test_set.shape)\n",
    "# print(train_set.shape)\n",
    "\n",
    "# test_set.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_2/test_set.csv')\n",
    "# train_set.to_csv('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_2/train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pk.dump(train_set, open('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_2/train_set.pkl', 'wb'))\n",
    "# pk.dump(test_set, open('./data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_2/test_set.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_2.columns.to_list())\n",
    "\n",
    "# s1 = df_2['Sequence'][0]\n",
    "# s2 = df_2['Sequence'][4]\n",
    "# diff = [i for i in range(len(s1)) if s1[i] != s2[i]]\n",
    "# print(diff)\n",
    "\n",
    "# s1 = df_2['Sequence'][0]\n",
    "# s2 = df_2['HC'][4]\n",
    "# print('s1 length:', len(s1), 's2 length:', len(s2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = df_2.iloc[0]\n",
    "# print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------\n",
    "#### Crafting a dataset for the sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FABSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Emits batches of characters\n",
    "    \"\"\"\n",
    "    def __init__(self, config, csv_file_path):\n",
    "        self.config = config\n",
    "        self.df = pd.read_csv(data_path, skiprows=6)\n",
    "        \n",
    "        # my_set = set()   \n",
    "        # def make_set(x):\n",
    "        #     for c in x:\n",
    "        #         my_set.add(c)\n",
    "\n",
    "        # self.df['Sequence'].apply(make_set)\n",
    "        # self.chars = sorted(list(my_set)) + [\"[MASK]\"]\n",
    "        # print('len of chars:', len(self.chars))\n",
    "        # print('chars:', self.chars)\n",
    "    \n",
    "        # 20 naturally occuring amino acids in human proteins plus MASK token\n",
    "        self.chars = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '[MASK]']\n",
    "        print('vocabulary:', self.chars)\n",
    "\n",
    "        data_size, vocab_size = self.df.shape[0], len(self.chars)\n",
    "        print('data has %d rows, %d vocab size (unique).' % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = { ch:i for i,ch in enumerate(self.chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(self.chars) }\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n",
    "\n",
    "    def get_block_size(self):\n",
    "        return self.config['block_size']\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0] #len(self.data) - self.config['block_size']\n",
    "\n",
    "    \"\"\" Returns data, mask pairs used for Masked Language Model training \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size) characters from the data\n",
    "        # chunk = self.data[idx:idx + self.config['block_size']]\n",
    "        chunk = self.df.loc[idx, 'Sequence']\n",
    "        \n",
    "        # encode every character to an integer\n",
    "        dix = torch.tensor([self.stoi[s] for s in chunk], dtype=torch.long)\n",
    "\n",
    "        # get number of tokens to mask\n",
    "        n_pred = max(1, int(round(self.config['block_size']*self.config['mask_prob'])))\n",
    "\n",
    "        # indices of the tokens that will be masked (a random selection of n_pred of the tokens)\n",
    "        masked_idx = torch.randperm(self.config['block_size'], dtype=torch.long, )[:n_pred]\n",
    "\n",
    "        mask = torch.zeros_like(dix)\n",
    "\n",
    "        # copy the actual tokens to the mask\n",
    "        mask[masked_idx] = dix[masked_idx]\n",
    "        \n",
    "        # ... and overwrite then with MASK token in the data\n",
    "        dix[masked_idx] = self.stoi[\"[MASK]\"]\n",
    "\n",
    "        return dix, mask \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/mit-ll/mit-ll-AlphaSeq_Antibody_Dataset-a8f64a9/antibody_dataset_2/MITLL_AAlphaBio_Ab_Binding_dataset2.csv'\n",
    "dataset = FABSequenceDataset(config, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.__len__())\n",
    "\n",
    "dix, mask = dataset.__getitem__(0)\n",
    "print(len(dix))\n",
    "print()\n",
    "print(len(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=config['batch_size'], shuffle=False, num_workers=5, \n",
    "                          pin_memory=True)\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "batch = next(data_iter)\n",
    "dix, mask = batch\n",
    "print(dix.shape)\n",
    "print(mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avm-dvm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
